{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Embedding, merge, Convolution2D, MaxPooling2D, Dropout, concatenate\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers.core import Reshape, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from data_helpers import load_data\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard  \n",
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pygoose import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project = kg.Project.discover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = kg.io.load(project.aux_dir + 'fasttext_vocab_embedding_matrix.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_descriptions = kg.io.load(project.preprocessed_data_dir + 'sequences_fasttext_train.pickle')\n",
    "X_test_descriptions = kg.io.load(project.preprocessed_data_dir + 'sequences_fasttext_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_titles = kg.io.load(project.preprocessed_data_dir + 'sequences_fasttext_titles_train.pickle')\n",
    "X_test_titles = kg.io.load(project.preprocessed_data_dir + 'sequences_fasttext_titles_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = kg.io.load(project.features_dir + 'y_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = kg.io.load(project.features_dir + 'y_test.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "y_train_encoded = np_utils.to_categorical(encoded_y_train)\n",
    "y_test_encoded = np_utils.to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length_descr = X_train_descriptions.shape[-1]\n",
    "sequence_length_titles = X_train_titles.shape[-1]\n",
    "sequence_length = sequence_length_descr + sequence_length_titles\n",
    "vocabulary_size = embedding_matrix.shape[0]\n",
    "embedding_dim = embedding_matrix.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 207481 45\n"
     ]
    }
   ],
   "source": [
    "print(embedding_dim, vocabulary_size, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5\n",
    "\n",
    "nb_epoch = 5\n",
    "batch_size = 30\n",
    "output_1_dim = 14\n",
    "output_2_dim = 166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN lvl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 300), data_format=\"channels_last\", activation=\"relu\", kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (4, 300), data_format=\"channels_last\", activation=\"relu\", kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (5, 300), data_format=\"channels_last\", activation=\"relu\", kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(28, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(27, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(26, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:34: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:30: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(13, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(12, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(11, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:48: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=14, activation=\"softmax\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "# this returns a tensor\n",
    "\n",
    "inputs_descr_1 = Input(shape=(sequence_length_descr,), dtype='int32')\n",
    "inputs_titles_1 = Input(shape=(sequence_length_titles,), dtype='int32')\n",
    "\n",
    "embedding_descr = Embedding(\n",
    "        vocabulary_size,\n",
    "        embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=sequence_length_descr,\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "embedding_titles = Embedding(\n",
    "        vocabulary_size,\n",
    "        embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=sequence_length_titles,\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_part(embedding_1, sequence_length):\n",
    "    reshape_1 = Reshape((sequence_length, embedding_dim, 1))(embedding_1)\n",
    "\n",
    "    conv_1_0 = Convolution2D(num_filters, filter_sizes[0], embedding_dim, border_mode='valid', init='normal', activation='relu', dim_ordering='tf')(reshape_1)\n",
    "    conv_1_1 = Convolution2D(num_filters, filter_sizes[1], embedding_dim, border_mode='valid', init='normal', activation='relu', dim_ordering='tf')(reshape_1)\n",
    "    conv_1_2 = Convolution2D(num_filters, filter_sizes[2], embedding_dim, border_mode='valid', init='normal', activation='relu', dim_ordering='tf')(reshape_1)\n",
    "\n",
    "    maxpool_1_0 = MaxPooling2D(pool_size=(sequence_length - filter_sizes[0] + 1, 1), strides=(1,1), border_mode='valid', dim_ordering='tf')(conv_1_0)\n",
    "    maxpool_1_1 = MaxPooling2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), border_mode='valid', dim_ordering='tf')(conv_1_1)\n",
    "    maxpool_1_2 = MaxPooling2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), border_mode='valid', dim_ordering='tf')(conv_1_2)\n",
    "\n",
    "    merged_tensor_1 = merge([maxpool_1_0, maxpool_1_1, maxpool_1_2], mode='concat', concat_axis=1)\n",
    "    flatten_1 = Flatten()(merged_tensor_1)\n",
    "    return flatten_1\n",
    "\n",
    "\n",
    "embedding_descr_1 = embedding_descr(inputs_descr_1)\n",
    "embedding_titles_1 = embedding_titles(inputs_titles_1)\n",
    "\n",
    "\n",
    "flatten_descr_1 = conv_part(embedding_descr_1, sequence_length_descr)\n",
    "flatten_titles_1 = conv_part(embedding_titles_1, sequence_length_titles)\n",
    "flatten_1 = concatenate([flatten_descr_1, flatten_titles_1])\n",
    "\n",
    "dropout_1 = Dropout(drop)(flatten_1)\n",
    "output_1 = Dense(output_dim=output_1_dim , activation='softmax')(dropout_1)\n",
    "\n",
    "\n",
    "# flatten_descr_2 = conv_part(embedding_descr_1, sequence_length_descr)\n",
    "# flatten_titles_2 = conv_part(embedding_titles_1, sequence_length_titles)\n",
    "\n",
    "# merged = concatenate([flatten_descr_2, flatten_titles_2, output_descr_1, output_titles_1])\n",
    "# dropout_2 = Dropout(drop)(merged)\n",
    "# output_2 = Dense(output_dim=output_2_dim , activation='softmax')(dropout_2)\n",
    "\n",
    "# this creates a model that includes\n",
    "model = Model(input=[inputs_descr_1, inputs_titles_1], output=output_1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "inputs_descr_1 (InputLayer)      (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "inputs_titles_1 (InputLayer)     (None, 15)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_descr (Embedding)      (None, 30, 300)       62244300    inputs_descr_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "embedding_titles (Embedding)     (None, 15, 300)       62244300    inputs_titles_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_54 (Reshape)             (None, 30, 300, 1)    0           embedding_descr[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_55 (Reshape)             (None, 15, 300, 1)    0           embedding_titles[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_descr_1_conv_1_0 (Conv2D (None, 28, 1, 512)    461312      reshape_54[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_descr_1_conv_1_1 (Conv2D (None, 27, 1, 512)    614912      reshape_54[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_descr_1_conv_1_2 (Conv2D (None, 26, 1, 512)    768512      reshape_54[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_titles_1_conv_1_0 (Conv2 (None, 13, 1, 512)    461312      reshape_55[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_titles_1_conv_1_1 (Conv2 (None, 12, 1, 512)    614912      reshape_55[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_titles_1_conv_1_2 (Conv2 (None, 11, 1, 512)    768512      reshape_55[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_descr_1_maxpool_1_0 (Max (None, 1, 1, 512)     0           flatten_descr_1_conv_1_0[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_descr_1_maxpool_1_1 (Max (None, 1, 1, 512)     0           flatten_descr_1_conv_1_1[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_descr_1_maxpool_1_2 (Max (None, 1, 1, 512)     0           flatten_descr_1_conv_1_2[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_titles_1_maxpool_1_0 (Ma (None, 1, 1, 512)     0           flatten_titles_1_conv_1_0[0][0]  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_titles_1_maxpool_1_1 (Ma (None, 1, 1, 512)     0           flatten_titles_1_conv_1_1[0][0]  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_titles_1_maxpool_1_2 (Ma (None, 1, 1, 512)     0           flatten_titles_1_conv_1_2[0][0]  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_descr_1_merged_tensor_1  (None, 3, 1, 512)     0           flatten_descr_1_maxpool_1_0[0][0]\n",
      "                                                                   flatten_descr_1_maxpool_1_1[0][0]\n",
      "                                                                   flatten_descr_1_maxpool_1_2[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "flatten_titles_1_merged_tensor_1 (None, 3, 1, 512)     0           flatten_titles_1_maxpool_1_0[0][0\n",
      "                                                                   flatten_titles_1_maxpool_1_1[0][0\n",
      "                                                                   flatten_titles_1_maxpool_1_2[0][0\n",
      "____________________________________________________________________________________________________\n",
      "flatten_descr_1_flatten_1 (Flatt (None, 1536)          0           flatten_descr_1_merged_tensor_1[0\n",
      "____________________________________________________________________________________________________\n",
      "flatten_titles_1_flatten_1 (Flat (None, 1536)          0           flatten_titles_1_merged_tensor_1[\n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Concatenate)          (None, 3072)          0           flatten_descr_1_flatten_1[0][0]  \n",
      "                                                                   flatten_titles_1_flatten_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)             (None, 3072)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_40 (Dense)                 (None, 14)            43022       dropout_41[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 128,221,094\n",
      "Trainable params: 3,732,494\n",
      "Non-trainable params: 124,488,600\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500000 samples, validate on 216675 samples\n",
      "Epoch 1/5\n",
      "500000/500000 [==============================] - 2242s - loss: 0.3822 - acc: 0.8880 - val_loss: 0.1961 - val_acc: 0.9430\n",
      "Epoch 2/5\n",
      "500000/500000 [==============================] - 2243s - loss: 0.2016 - acc: 0.9418 - val_loss: 0.1637 - val_acc: 0.9531\n",
      "Epoch 3/5\n",
      "500000/500000 [==============================] - 2243s - loss: 0.1506 - acc: 0.9564 - val_loss: 0.1513 - val_acc: 0.9566\n",
      "Epoch 4/5\n",
      "500000/500000 [==============================] - 2233s - loss: 0.1171 - acc: 0.9659 - val_loss: 0.1491 - val_acc: 0.9575\n",
      "Epoch 5/5\n",
      "500000/500000 [==============================] - 2230s - loss: 0.0930 - acc: 0.9729 - val_loss: 0.1472 - val_acc: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f32dba515f8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train_descriptions, X_train_titles], y_train_encoded, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, callbacks=[tensorboard], validation_data=([X_test_descriptions, X_test_titles], y_test_encoded))  # starts training1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "helpers.serialize_model(model, './CNN_lvl1_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py:1242: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('./CNN_lvl1_model/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./CNN_lvl1_model/model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216675/216675 [==============================] - 314s   \n",
      "\n",
      "\n",
      "Test score: 2.8114139884\n",
      "Test accuracy: 0.112638748288\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate([X_test_descriptions, X_test_titles], y_test_encoded,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lvl1_answers_train = model.predict([X_train_descriptions, X_train_titles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lvl1_answers_test = model.predict([X_test_descriptions, X_test_titles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lvl1_answers_train = helpers.get_file('./CNN_lvl1_model/answers_lvl1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lvl1_answers_test = helpers.get_file('./CNN_lvl1_model/answers_test_lvl1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./CNN_lvl1_model/answers_test_lvl1', lvl1_answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./CNN_lvl1_model/answers_train_lvl1', lvl1_answers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lvl1_answers_test = np.load('./CNN_lvl1_model/answers_test_lvl1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216675"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lvl1_answers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN lvl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(project.data_dir + 'train.csv').fillna('none')\n",
    "df_test = pd.read_csv(project.data_dir + 'test.csv').fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_lvl2 = list(df_train['lvl2'])\n",
    "y_test_lvl2 = list(df_test['lvl2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_lvl2 = LabelEncoder()\n",
    "encoder_lvl2.fit(y_train_lvl2)\n",
    "encoded_y_train_lvl2 = encoder_lvl2.transform(y_train_lvl2)\n",
    "encoded_y_test_lvl2 = encoder_lvl2.transform(y_test_lvl2)\n",
    "y_train_encoded_lvl2 = np_utils.to_categorical(encoded_y_train_lvl2)\n",
    "y_test_encoded_lvl2 = np_utils.to_categorical(encoded_y_test_lvl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 300), data_format=\"channels_last\", activation=\"relu\", kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (4, 300), data_format=\"channels_last\", activation=\"relu\", kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (5, 300), data_format=\"channels_last\", activation=\"relu\", kernel_initializer=\"normal\", padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(28, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(27, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(26, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:31: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(13, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(12, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(11, 1), data_format=\"channels_last\", strides=(1, 1), padding=\"valid\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=166, activation=\"softmax\")`\n",
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "inputs_descr_1 = Input(shape=(sequence_length_descr,), dtype='int32')\n",
    "inputs_titles_1 = Input(shape=(sequence_length_titles,), dtype='int32')\n",
    "\n",
    "embedding_descr = Embedding(\n",
    "        vocabulary_size,\n",
    "        embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=sequence_length_descr,\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "embedding_titles = Embedding(\n",
    "        vocabulary_size,\n",
    "        embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=sequence_length_titles,\n",
    "        trainable=False,\n",
    "    )\n",
    "\n",
    "def conv_part(embedding_1, sequence_length):\n",
    "    reshape_1 = Reshape((sequence_length, embedding_dim, 1))(embedding_1)\n",
    "\n",
    "    conv_1_0 = Convolution2D(num_filters, filter_sizes[0], embedding_dim, border_mode='valid', init='normal', activation='relu', dim_ordering='tf')(reshape_1)\n",
    "    conv_1_1 = Convolution2D(num_filters, filter_sizes[1], embedding_dim, border_mode='valid', init='normal', activation='relu', dim_ordering='tf')(reshape_1)\n",
    "    conv_1_2 = Convolution2D(num_filters, filter_sizes[2], embedding_dim, border_mode='valid', init='normal', activation='relu', dim_ordering='tf')(reshape_1)\n",
    "\n",
    "    maxpool_1_0 = MaxPooling2D(pool_size=(sequence_length - filter_sizes[0] + 1, 1), strides=(1,1), border_mode='valid', dim_ordering='tf')(conv_1_0)\n",
    "    maxpool_1_1 = MaxPooling2D(pool_size=(sequence_length - filter_sizes[1] + 1, 1), strides=(1,1), border_mode='valid', dim_ordering='tf')(conv_1_1)\n",
    "    maxpool_1_2 = MaxPooling2D(pool_size=(sequence_length - filter_sizes[2] + 1, 1), strides=(1,1), border_mode='valid', dim_ordering='tf')(conv_1_2)\n",
    "\n",
    "    merged_tensor_1 = merge([maxpool_1_0, maxpool_1_1, maxpool_1_2], mode='concat', concat_axis=1)\n",
    "    flatten_1 = Flatten()(merged_tensor_1)\n",
    "    return flatten_1\n",
    "\n",
    "\n",
    "embedding_descr_1 = embedding_descr(inputs_descr_1)\n",
    "embedding_titles_1 = embedding_titles(inputs_titles_1)\n",
    "\n",
    "flatten_descr_2 = conv_part(embedding_descr_1, sequence_length_descr)\n",
    "flatten_titles_2 = conv_part(embedding_titles_1, sequence_length_titles)\n",
    "flatten_2 = concatenate([flatten_descr_2, flatten_titles_2])\n",
    "\n",
    "dropout_2 = Dropout(drop)(flatten_2)\n",
    "\n",
    "output_2 = Dense(output_dim=output_2_dim , activation='softmax')(dropout_2)\n",
    "\n",
    "model_2 = Model(input=[inputs_descr_1, inputs_titles_1], output=output_2)\n",
    "\n",
    "checkpoint = ModelCheckpoint('CNN-text-classification-keras/logs/weights.{epoch:03d}-{val_acc:.4f}.hdf5', \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='auto')\n",
    "\n",
    "adam = Adam(lr=1e-4, \n",
    "            beta_1=0.9, \n",
    "            beta_2=0.999, \n",
    "            epsilon=1e-08)\n",
    "\n",
    "model_2.compile(optimizer=adam, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_11 (InputLayer)            (None, 30)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (None, 15)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)         (None, 30, 300)       62244300    input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)         (None, 15, 300)       62244300    input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)              (None, 30, 300, 1)    0           embedding_11[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)              (None, 15, 300, 1)    0           embedding_12[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 28, 1, 512)    461312      reshape_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 27, 1, 512)    614912      reshape_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 26, 1, 512)    768512      reshape_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 13, 1, 512)    461312      reshape_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 12, 1, 512)    614912      reshape_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 11, 1, 512)    768512      reshape_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D)  (None, 1, 1, 512)     0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D)  (None, 1, 1, 512)     0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D)  (None, 1, 1, 512)     0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D)  (None, 1, 1, 512)     0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D)  (None, 1, 1, 512)     0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D)  (None, 1, 1, 512)     0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 3, 1, 512)     0           max_pooling2d_22[0][0]           \n",
      "                                                                   max_pooling2d_23[0][0]           \n",
      "                                                                   max_pooling2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_9 (Merge)                  (None, 3, 1, 512)     0           max_pooling2d_25[0][0]           \n",
      "                                                                   max_pooling2d_26[0][0]           \n",
      "                                                                   max_pooling2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 1536)          0           merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)              (None, 1536)          0           merge_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 3072)          0           flatten_7[0][0]                  \n",
      "                                                                   flatten_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 3072)          0           concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 166)           510118      dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 128,688,190\n",
      "Trainable params: 4,199,590\n",
      "Non-trainable params: 124,488,600\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "plot_model(model_2, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: KeysView(<HDF5 file \"model.h5\" (mode r)>)\n"
     ]
    }
   ],
   "source": [
    "# import h5py\n",
    "# filename = './CNN_lvl2_model/model.h5'\n",
    "# f = h5py.File(filename, 'r')\n",
    "\n",
    "# # List all groups\n",
    "# print(\"Keys: %s\" % f.keys())\n",
    "# a_group_key = list(f.keys())\n",
    "\n",
    "# for index,key in enumerate(a_group_key[:10]):\n",
    "#     print(index, key)\n",
    "#     data = np.array(f[key].values())\n",
    "    \n",
    "# list(f['flatten_descr_1_conv_1_0'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denys/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500000 samples, validate on 216675 samples\n",
      "Epoch 1/5\n",
      "500000/500000 [==============================] - 2300s - loss: 0.4453 - top_k_categorical_accuracy: 0.9762 - val_loss: 0.5404 - val_top_k_categorical_accuracy: 0.9637\n",
      "Epoch 2/5\n",
      "500000/500000 [==============================] - 2304s - loss: 0.4027 - top_k_categorical_accuracy: 0.9804 - val_loss: 0.5443 - val_top_k_categorical_accuracy: 0.9634\n",
      "Epoch 3/5\n",
      "500000/500000 [==============================] - 2295s - loss: 0.3671 - top_k_categorical_accuracy: 0.9838 - val_loss: 0.5427 - val_top_k_categorical_accuracy: 0.9640\n",
      "Epoch 4/5\n",
      "282570/500000 [===============>..............] - ETA: 858s - loss: 0.3276 - top_k_categorical_accuracy: 0.9871"
     ]
    }
   ],
   "source": [
    "model_2.fit([X_train_descriptions, X_train_titles], y_train_encoded_lvl2, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, callbacks=[tensorboard], validation_data=([X_test_descriptions, X_test_titles], y_test_encoded_lvl2))  # starts training1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = model_2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.save_file(weights, './CNN_lvl2_model/weights_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model_2.to_json()\n",
    "with open(\"./CNN_lvl2_model/model_final.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "helpers.serialize_model(model_2, './CNN_lvl2_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216660/216675 [============================>.] - ETA: 0s\n",
      "\n",
      "Test score: 5.50227687247\n",
      "Test accuracy: 0.0356801676875\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate([X_test_descriptions, X_test_titles, lvl1_answers_test], y_test_encoded_lvl2,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   3,   4,   5,   6,   7,   8,   9,  27,  40,  47,  59, 110, 140])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11,  12,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,\n",
       "        25,  26,  29,  30,  31,  33,  34,  35,  36,  37,  38,  40,  42,\n",
       "        43,  44,  45,  46,  51,  53,  55,  56,  57,  60,  61,  62,  64,\n",
       "        65,  66,  67,  70,  71,  72,  73,  74,  75,  76,  78,  79,  80,\n",
       "        81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "        94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
       "       107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "       134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147,\n",
       "       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
       "       162, 165, 166, 167, 168, 169, 172, 249, 250, 251, 252, 253, 254,\n",
       "       255, 256, 257, 258, 259, 265, 266, 267, 268, 269, 270, 272, 273,\n",
       "       274, 275, 278, 279, 280, 281, 282, 283, 284, 285])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_lvl2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lvl2_answers_test = loaded_model.predict([X_test_descriptions, X_test_titles, lvl1_answers_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./CNN_lvl2_model/lvl2_answers_test', lvl1_answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_3_accuracy(y_test, predict_proba):\n",
    "    predictions = helpers.get_prediction_with_precision(encoder_lvl2.classes_, predict_proba, 1, True)\n",
    "    answer = [1 if y_test[i] in predictions[i] else 0 for i in range(len(predictions))]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = top_3_accuracy(y_test_lvl2, lvl2_answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861271489558094"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answer)/len(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216630/216675 [============================>.] - ETA: 0s\n",
      "\n",
      "Test score: 0.2452411565\n",
      "Test accuracy: 0.935054794832\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_encoded,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('../data/features/CNN_lvl1_proba_test', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction_with_precision(classes, predict_proba, cat_num=3, with_proba=False):\n",
    "    predictions_proba = predict_proba\n",
    "    return [\n",
    "        [\n",
    "            (\n",
    "                classes[pos], proba[pos]\n",
    "            )\n",
    "            for pos, proba in sorted(\n",
    "                enumerate(predictions),\n",
    "                key=lambda arg: arg[1], reverse=True\n",
    "            )[:cat_num]\n",
    "        ]\n",
    "        if with_proba is False\n",
    "        else\n",
    "        [\n",
    "            (\n",
    "                classes[pos]\n",
    "            )\n",
    "            for pos, proba in sorted(\n",
    "                enumerate(predictions),\n",
    "                key=lambda arg: arg[1], reverse=True\n",
    "            )[:cat_num]\n",
    "        ]\n",
    "        for i, predictions in enumerate(predictions_proba)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = get_prediction_with_precision(classes, predicted, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = [item for sublist in predicted for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.94      0.93     15503\n",
      "          3       0.90      0.89      0.89     15483\n",
      "          4       0.87      0.90      0.88     21531\n",
      "          5       0.98      0.97      0.98     56622\n",
      "          6       0.98      0.96      0.97     24020\n",
      "          7       0.90      0.87      0.89       882\n",
      "          8       0.75      0.75      0.75      2660\n",
      "          9       0.98      0.98      0.98     16454\n",
      "         27       0.91      0.93      0.92     12137\n",
      "         40       0.76      0.27      0.40       239\n",
      "         47       0.98      0.96      0.97     28935\n",
      "         59       0.85      0.76      0.81      3649\n",
      "        110       0.88      0.97      0.93     11497\n",
      "        140       0.72      0.69      0.70      7063\n",
      "\n",
      "avg / total       0.94      0.94      0.93    216675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14501   551   127   103    63     1    28    16    20     0     2    13\n",
      "     32    46]\n",
      " [  670 13738   478    78    73     1   127     9    46     0    12     5\n",
      "     44   202]\n",
      " [  143   447 19293   196   176    32    99    75   324     1    31    63\n",
      "     76   575]\n",
      " [   83    79   303 55144    27     4    98    20   269     1    10   297\n",
      "    104   183]\n",
      " [  195   110   319    37 23065     2    37    53    16     1     7    17\n",
      "     42   119]\n",
      " [    5     1    49    13     2   766     0    12     9     0     0     3\n",
      "      8    14]\n",
      " [   27   136   165    69    20     3  1998     5    41     3    12    20\n",
      "     50   111]\n",
      " [    8     8    95    23    19     3     2 16148     1     0     7     1\n",
      "     45    94]\n",
      " [   23    24   282   180    17     1    53    12 11333    14     9    33\n",
      "     35   121]\n",
      " [    1     3    14     1     0     0    91     0    56    65     1     2\n",
      "      0     5]\n",
      " [    4     8    48    14    10     4    13    37    19     0 27713     2\n",
      "    763   300]\n",
      " [   34    26   191   404    22     3    50     1    89     0     2  2788\n",
      "     14    25]\n",
      " [    2     7    24     8     4     1    12    12    11     0   139     3\n",
      "  11177    97]\n",
      " [   28   178   807   112   114    28    62   123   197     0   259    14\n",
      "    267  4874]]\n"
     ]
    }
   ],
   "source": [
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### serialize model to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
