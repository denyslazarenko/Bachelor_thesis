\select@language {russian}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Classes, training set, and test set in text classification.\relax }}{8}{figure.caption.3}
\contentsline {figure}{\numberline {1.2}{\ignorespaces Supervised learning work flow.\relax }}{9}{figure.caption.4}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Naive Bayes algorithm (multinomial model): Training and testing.\relax }}{11}{figure.caption.5}
\contentsline {figure}{\numberline {1.4}{\ignorespaces .\relax }}{12}{figure.caption.6}
\contentsline {figure}{\numberline {1.5}{\ignorespaces .\relax }}{13}{figure.caption.7}
\contentsline {figure}{\numberline {1.6}{\ignorespaces .\relax }}{13}{figure.caption.8}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Neural Network\relax }}{19}{figure.caption.10}
\contentsline {figure}{\numberline {2.2}{\ignorespaces The Skip-gram model architecture.\relax }}{22}{figure.caption.11}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Words representation\relax }}{24}{figure.caption.12}
\contentsline {figure}{\numberline {2.4}{\ignorespaces The CBOW model architecture.\relax }}{26}{figure.caption.13}
\contentsline {figure}{\numberline {2.5}{\ignorespaces Convolution Neural Networks architecture for text classification\relax }}{27}{figure.caption.14}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Basic variables which are used in the convolution layer\relax }}{27}{figure.caption.15}
\contentsline {figure}{\numberline {2.7}{\ignorespaces ReLu activation function\relax }}{28}{figure.caption.16}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Max pulling layer\relax }}{29}{figure.caption.17}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Fully connected layer of CNN\relax }}{30}{figure.caption.18}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Back propagation through max pulling layer\relax }}{31}{figure.caption.19}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Back propagation through convolution layer\relax }}{32}{figure.caption.20}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Neural Network\relax }}{37}{figure.caption.22}
\contentsline {figure}{\numberline {4.2}{\ignorespaces The Skip-gram model architecture.\relax }}{40}{figure.caption.23}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Words representation\relax }}{42}{figure.caption.24}
\contentsline {figure}{\numberline {4.4}{\ignorespaces The CBOW model architecture.\relax }}{44}{figure.caption.25}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Convolution Neural Networks architecture for text classification\relax }}{45}{figure.caption.26}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Basic variables which are used in the convolution layer\relax }}{45}{figure.caption.27}
\contentsline {figure}{\numberline {4.7}{\ignorespaces ReLu activation function\relax }}{46}{figure.caption.28}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Max pulling layer\relax }}{47}{figure.caption.29}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Fully connected layer of CNN\relax }}{48}{figure.caption.30}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Back propagation through max pulling layer\relax }}{49}{figure.caption.31}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Back propagation through convolution layer\relax }}{50}{figure.caption.32}
\addvspace {10\p@ }
\addvspace {10\p@ }
