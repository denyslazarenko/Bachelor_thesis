\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\ttlp@append[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{../BibTeX-Styles/utf8gost71u}
\@writefile{toc}{~\hfill {p.}\par }
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{ABBREVIATIONS}{6}{chapter*.3}}
\@writefile{toc}{\contentsline {chapter}{INTRODUCTION}{7}{chapter*.4}}
\citation{manning}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}TEXT CLASSIFICATION}{9}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt1}{{1}{9}{TEXT CLASSIFICATION}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Statement of the classification problem}{9}{section.1.1}}
\newlabel{sect1_2}{{1.1}{9}{Statement of the classification problem}{section.1.1}{}}
\newlabel{eq:equation3}{{1.1}{9}{Statement of the classification problem}{equation.1.1.1}{}}
\newlabel{eq:equation4}{{1.2}{9}{Statement of the classification problem}{equation.1.1.2}{}}
\citation{foundationsml}
\citation{NB1}
\citation{NB2}
\citation{LR}
\citation{svm}
\citation{manning}
\citation{manning}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Classes, training set, and test set in text classification.\relax }}{10}{figure.caption.5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{img:hierarchy}{{1.1}{10}{Classes, training set, and test set in text classification.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Short review of existing mathematical model which can be used to solve the classification problem}{10}{section.1.2}}
\newlabel{sect1_3}{{1.2}{10}{Short review of existing mathematical model which can be used to solve the classification problem}{section.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Supervised learning workflow.\relax }}{11}{figure.caption.6}}
\newlabel{img:supervised_learning_work_flow}{{1.2}{11}{Supervised learning workflow.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Model evaluation and validation}{11}{section.1.3}}
\newlabel{sect1_4}{{1.3}{11}{Model evaluation and validation}{section.1.3}{}}
\citation{model_evaluation}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Model Evaluation Applications}{12}{subsection.1.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Model Evaluation Techniques}{12}{subsection.1.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Holdout method\relax }}{13}{figure.caption.7}}
\newlabel{img:eval3}{{1.3}{13}{Holdout method\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Classification metrics}{13}{section.1.4}}
\newlabel{accuracy}{{1.3}{13}{Classification metrics}{equation.1.4.3}{}}
\newlabel{img:CM}{{\caption@xref {img:CM}{ on input line 134}}{14}{Classification metrics}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Confusion matrix\relax }}{14}{figure.caption.8}}
\newlabel{precision}{{1.4}{14}{Classification metrics}{equation.1.4.4}{}}
\newlabel{recall}{{1.5}{14}{Classification metrics}{equation.1.4.5}{}}
\newlabel{f1}{{1.6}{15}{Classification metrics}{equation.1.4.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Summary of the section}{15}{section.1.5}}
\citation{jurafsky}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}\uppercase {Mathematical models and algorithms for text classification}}{16}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt2}{{2}{16}{\uppercase {Mathematical models and algorithms for text classification}}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Words representations}{16}{section.2.1}}
\newlabel{sect2_1}{{2.1}{16}{Words representations}{section.2.1}{}}
\newlabel{eq:equation1}{{2.1}{16}{Words representations}{equation.2.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Bag-of-Words Approach}{16}{subsection.2.1.1}}
\newlabel{subsect2_1_1}{{2.1.1}{16}{Bag-of-Words Approach}{subsection.2.1.1}{}}
\citation{jurafsky}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Feature vector\relax }}{17}{table.caption.9}}
\newlabel{Ts0Sib_}{{2.1}{17}{Feature vector\relax }{table.caption.9}{}}
\citation{embeddings_1}
\citation{embeddings_2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}TF-IDF Approach}{18}{subsection.2.1.2}}
\newlabel{subsect2_1_2}{{2.1.2}{18}{TF-IDF Approach}{subsection.2.1.2}{}}
\newlabel{eq:equation2_2}{{2.2}{18}{TF-IDF Approach}{equation.2.1.2}{}}
\newlabel{eq:equation2_3}{{2.3}{18}{TF-IDF Approach}{equation.2.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Embeddings}{18}{subsection.2.1.3}}
\newlabel{subsect2_1_3}{{2.1.3}{18}{Embeddings}{subsection.2.1.3}{}}
\newlabel{eq:equation2_4}{{2.4}{19}{Embeddings}{equation.2.1.4}{}}
\newlabel{eq:equation2_5}{{2.5}{19}{Embeddings}{equation.2.1.5}{}}
\newlabel{eq:equation2_6}{{2.6}{19}{Embeddings}{equation.2.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Neural Network\relax }}{19}{figure.caption.10}}
\newlabel{img:FCNN}{{2.1}{19}{Neural Network\relax }{figure.caption.10}{}}
\newlabel{eq:equation2_8}{{2.7}{19}{Embeddings}{equation.2.1.7}{}}
\newlabel{eq:equation_CE_2}{{2.8}{19}{Embeddings}{equation.2.1.8}{}}
\newlabel{eq:equation_CE_3}{{2.10}{20}{Embeddings}{equation.2.1.10}{}}
\newlabel{eq:equation_CE_4}{{2.11}{20}{Embeddings}{equation.2.1.11}{}}
\newlabel{eq:CE_gradient}{{2.12}{20}{Embeddings}{equation.2.1.12}{}}
\newlabel{eq:equation_CE_5}{{2.13}{20}{Embeddings}{equation.2.1.13}{}}
\citation{embeddings_2}
\newlabel{eq:equation2_7}{{2.16}{21}{Embeddings}{equation.2.1.16}{}}
\newlabel{eq:equation2_10}{{2.17}{21}{Embeddings}{equation.2.1.17}{}}
\newlabel{eq:equation2_11}{{2.19}{21}{Embeddings}{equation.2.1.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The Skip-gram model architecture.\relax }}{22}{figure.caption.11}}
\newlabel{img:skip_gram_model}{{2.2}{22}{The Skip-gram model architecture.\relax }{figure.caption.11}{}}
\newlabel{eq:indicator}{{2.26}{23}{Embeddings}{equation.2.1.26}{}}
\citation{assignment1}
\citation{embeddings_2}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Words representation\relax }}{25}{figure.caption.12}}
\newlabel{img:embed}{{2.3}{25}{Words representation\relax }{figure.caption.12}{}}
\citation{CNN}
\citation{Kalchbrenner}
\citation{CNN}
\citation{CNN}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces The CBOW model architecture.\relax }}{26}{figure.caption.13}}
\newlabel{img:CBOW}{{2.4}{26}{The CBOW model architecture.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Deep learning algorithms for text classification}{26}{section.2.2}}
\newlabel{sect2_2}{{2.2}{26}{Deep learning algorithms for text classification}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Convolution Neural Networks}{26}{subsection.2.2.1}}
\newlabel{sect2_2_1}{{2.2.1}{26}{Convolution Neural Networks}{subsection.2.2.1}{}}
\citation{CNN_habr}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Convolution Neural Networks architecture for text classification\relax }}{27}{figure.caption.14}}
\newlabel{img:CNN}{{2.5}{27}{Convolution Neural Networks architecture for text classification\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{Convolution}{27}{figure.caption.14}}
\newlabel{sect2_2_1_1}{{2.2.1}{27}{Convolution}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Basic variables used in the convolution layer\relax }}{27}{figure.caption.15}}
\newlabel{img:convolution}{{2.6}{27}{Basic variables used in the convolution layer\relax }{figure.caption.15}{}}
\newlabel{eq:convolution}{{2.35}{28}{Convolution}{equation.2.2.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{Activation functions}{28}{equation.2.2.35}}
\newlabel{eq:Relu}{{2.36}{28}{Activation functions}{equation.2.2.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces ReLu activation function\relax }}{29}{figure.caption.16}}
\newlabel{img:Relu}{{2.7}{29}{ReLu activation function\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{Max pulling layer}{29}{figure.caption.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Max pulling layer\relax }}{29}{figure.caption.17}}
\newlabel{img:max_pulling}{{2.8}{29}{Max pulling layer\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{Fully connected layer}{30}{figure.caption.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Fully connected layer of CNN\relax }}{30}{figure.caption.18}}
\newlabel{img:CNN_FNN_layer}{{2.9}{30}{Fully connected layer of CNN\relax }{figure.caption.18}{}}
\newlabel{eq:CNN_softmax_grad}{{2.39}{30}{Fully connected layer}{equation.2.2.39}{}}
\newlabel{eq:CNN_softmax_grad_long}{{2.40}{31}{Fully connected layer}{equation.2.2.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Back propagation through max pulling layer\relax }}{31}{figure.caption.19}}
\newlabel{img:backprog_max_pulling}{{2.10}{31}{Back propagation through max pulling layer\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Back propagation through convolution layer\relax }}{32}{figure.caption.20}}
\newlabel{img:conv_grad}{{2.11}{32}{Back propagation through convolution layer\relax }{figure.caption.20}{}}
\citation{wiki_def_rnn}
\citation{colah_lstm}
\citation{rnn_problems}
\citation{colah_lstm}
\citation{colah_lstm}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Recurrent neural networks and their modifications}{33}{subsection.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces The structure of Recurrent neural network\relax }}{33}{figure.caption.21}}
\newlabel{img:rnn_structure}{{2.12}{33}{The structure of Recurrent neural network\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces The architecture of Recurrent neural network\relax }}{34}{figure.caption.22}}
\newlabel{img:SimpleRNN}{{2.13}{34}{The architecture of Recurrent neural network\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces The architecture of Long Short Term Memory neural network\relax }}{34}{figure.caption.23}}
\newlabel{img:LSTM}{{2.14}{34}{The architecture of Long Short Term Memory neural network\relax }{figure.caption.23}{}}
\citation{colah_lstm}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Advantages and drawbacks of different architectures}{35}{subsection.2.2.3}}
\citation{wildml}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Summary of the section}{36}{subsection.2.2.4}}
\citation{fasttext}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}\uppercase {Testing and practical application of text classification using software}}{37}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt3}{{3}{37}{\uppercase {Testing and practical application of text classification using software}}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Software selection}{37}{section.3.1}}
\newlabel{sect3_1}{{3.1}{37}{Software selection}{section.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Dataset selection and exploration}{38}{section.3.2}}
\newlabel{sect3_2}{{3.2}{38}{Dataset selection and exploration}{section.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces The hierarchy of categories\relax }}{38}{table.caption.24}}
\newlabel{my-label}{{3.1}{38}{The hierarchy of categories\relax }{table.caption.24}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Structure of the data files\relax }}{39}{table.caption.25}}
\newlabel{data_structure}{{3.2}{39}{Structure of the data files\relax }{table.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces Training set general information\relax }}{39}{table.caption.26}}
\newlabel{general}{{3.3}{39}{Training set general information\relax }{table.caption.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.5}{\ignorespaces Information about second-level categories\relax }}{39}{table.caption.28}}
\newlabel{my-label}{{3.5}{39}{Information about second-level categories\relax }{table.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.4}{\ignorespaces Information about first-level categories\relax }}{40}{table.caption.27}}
\newlabel{lvl1}{{3.4}{40}{Information about first-level categories\relax }{table.caption.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.6}{\ignorespaces Information about categorical features\relax }}{40}{table.caption.29}}
\newlabel{my-label}{{3.6}{40}{Information about categorical features\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Data preparation}{41}{section.3.3}}
\newlabel{sect3_3}{{3.3}{41}{Data preparation}{section.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Simplified event structure of data preprocessing\relax }}{41}{figure.caption.30}}
\newlabel{img:p3_preprocessing}{{3.1}{41}{Simplified event structure of data preprocessing\relax }{figure.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.7}{\ignorespaces Simplified event structure of data preprocessing\relax }}{42}{table.caption.31}}
\newlabel{my-label}{{3.7}{42}{Simplified event structure of data preprocessing\relax }{table.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Build embeddings structure\relax }}{43}{figure.caption.32}}
\newlabel{img:p3_sequences_fasttext}{{3.2}{43}{Build embeddings structure\relax }{figure.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.8}{\ignorespaces Simplified event structure of data preprocessing\relax }}{43}{table.caption.33}}
\newlabel{my-label}{{3.8}{43}{Simplified event structure of data preprocessing\relax }{table.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Network design and training}{44}{section.3.4}}
\newlabel{sect3_4}{{3.4}{44}{Network design and training}{section.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Train model structure\relax }}{44}{figure.caption.34}}
\newlabel{img:p3_train}{{3.3}{44}{Train model structure\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Metrics which were logged\relax }}{45}{figure.caption.35}}
\newlabel{img:p3_custom_callbacks}{{3.4}{45}{Metrics which were logged\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Summary of the section}{45}{section.3.5}}
\newlabel{sect3_5}{{3.5}{45}{Summary of the section}{section.3.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}\uppercase {Classification results evaluation}}{46}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapt4}{{4}{46}{\uppercase {Classification results evaluation}}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}General steps}{46}{section.4.1}}
\newlabel{sect4_1}{{4.1}{46}{General steps}{section.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Base line model}{46}{section.4.2}}
\newlabel{sect4_2}{{4.2}{46}{Base line model}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Architectures of Bi-LSTM models with 100 units \relax }}{47}{figure.caption.36}}
\newlabel{img:part4-bilstm}{{4.1}{47}{Architectures of Bi-LSTM models with 100 units \relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Models train and validation categorical accuracy by epochs\relax }}{48}{figure.caption.37}}
\newlabel{img:/bilstm_val_category_accuracy}{{4.2}{48}{Models train and validation categorical accuracy by epochs\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Models train and validation category crossentropy by epochs\relax }}{49}{figure.caption.38}}
\newlabel{img:bilstm_val_category_crossentropy}{{4.3}{49}{Models train and validation category crossentropy by epochs\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Models train and validation top k accuracy by epochs\relax }}{49}{figure.caption.39}}
\newlabel{img:bilstm_val_top_k_accuracy}{{4.4}{49}{Models train and validation top k accuracy by epochs\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Models batch time by epochs\relax }}{50}{figure.caption.40}}
\newlabel{img:bilstm_timing}{{4.5}{50}{Models batch time by epochs\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Bi-LSTM 100 units. Histogram of output from forward recurrent layers (a); histogram of weights from backward recurrent layers (b)\relax }}{50}{figure.caption.41}}
\newlabel{img:Bi-LSTM 100 units. Histogram of output from forward recurrent}{{4.6}{50}{Bi-LSTM 100 units. Histogram of output from forward recurrent layers (a); histogram of weights from backward recurrent layers (b)\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Bi-LSTM 100 units. Histogram of weights from first FFNN layer.\relax }}{51}{figure.caption.42}}
\newlabel{img:bilstm_dense}{{4.7}{51}{Bi-LSTM 100 units. Histogram of weights from first FFNN layer.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces CPU resources which were used while training Bi-LSTM NN.\relax }}{51}{figure.caption.43}}
\newlabel{img:resources_BILSTM}{{4.8}{51}{CPU resources which were used while training Bi-LSTM NN.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Convolution neural network}{52}{section.4.3}}
\newlabel{sect4_3}{{4.3}{52}{Convolution neural network}{section.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Analysis of categorical accuracy\relax }}{52}{table.caption.44}}
\newlabel{my-label}{{4.1}{52}{Analysis of categorical accuracy\relax }{table.caption.44}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Analysis of category crossentropy\relax }}{52}{table.caption.46}}
\newlabel{my-label}{{4.2}{52}{Analysis of category crossentropy\relax }{table.caption.46}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Analysis of top k accuracy\relax }}{52}{table.caption.48}}
\newlabel{my-label}{{4.3}{52}{Analysis of top k accuracy\relax }{table.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Models train and validation categorical accuracy by epochs\relax }}{53}{figure.caption.45}}
\newlabel{img:3CNN_categorical_accuracy}{{4.9}{53}{Models train and validation categorical accuracy by epochs\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Models train and validation category crossentropy by epochs\relax }}{53}{figure.caption.47}}
\newlabel{img:3CNN_category_crossentropy}{{4.10}{53}{Models train and validation category crossentropy by epochs\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Models train and validation top k accuracy by epochs\relax }}{54}{figure.caption.49}}
\newlabel{img:3CNN_top_k_accuracy}{{4.11}{54}{Models train and validation top k accuracy by epochs\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Models batch time by epochs\relax }}{54}{figure.caption.50}}
\newlabel{img:3CNN_timing}{{4.12}{54}{Models batch time by epochs\relax }{figure.caption.50}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces Convolutional model (a) 128;(b) 256; (c) 512 filters for each sizes [3, 4, 5]. Histogram of convolution layers\relax }}{55}{figure.caption.51}}
\newlabel{img:3CNN_conv_layers}{{4.13}{55}{Convolutional model (a) 128;(b) 256; (c) 512 filters for each sizes [3, 4, 5]. Histogram of convolution layers\relax }{figure.caption.51}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Convolutional model (a) 128;(b) 256; (c) 512 filters for each sizes [3, 4, 5]. Histogram of merged layers\relax }}{56}{figure.caption.52}}
\newlabel{img:3CNN_merged_layers}{{4.14}{56}{Convolutional model (a) 128;(b) 256; (c) 512 filters for each sizes [3, 4, 5]. Histogram of merged layers\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.15}{\ignorespaces Convolutional model (a) 128;(b) 256; (c) 512 filters for each sizes [3, 4, 5]. Histogram of dense layers\relax }}{57}{figure.caption.53}}
\newlabel{img:3CNN_dense_layers}{{4.15}{57}{Convolutional model (a) 128;(b) 256; (c) 512 filters for each sizes [3, 4, 5]. Histogram of dense layers\relax }{figure.caption.53}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.16}{\ignorespaces CPU resources which were used while training CNN.\relax }}{58}{figure.caption.54}}
\newlabel{img:resources_CNN}{{4.16}{58}{CPU resources which were used while training CNN.\relax }{figure.caption.54}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Convolution neural network with different regularization}{59}{section.4.4}}
\newlabel{sect4_4}{{4.4}{59}{Convolution neural network with different regularization}{section.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Analysis of categorical accuracy\relax }}{59}{table.caption.55}}
\newlabel{my-label}{{4.4}{59}{Analysis of categorical accuracy\relax }{table.caption.55}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Analysis of categorical cross entropy\relax }}{59}{table.caption.56}}
\newlabel{my-label}{{4.5}{59}{Analysis of categorical cross entropy\relax }{table.caption.56}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Analysis of top k accuracy\relax }}{60}{table.caption.57}}
\newlabel{my-label}{{4.6}{60}{Analysis of top k accuracy\relax }{table.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.17}{\ignorespaces Models train and validation categorical accuracy by epochs\relax }}{60}{figure.caption.58}}
\newlabel{img:4CNN_categorical_accuracy}{{4.17}{60}{Models train and validation categorical accuracy by epochs\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.18}{\ignorespaces Models train and validation category crossentropy by epochs\relax }}{61}{figure.caption.59}}
\newlabel{img:4CNN_category_crossentropy}{{4.18}{61}{Models train and validation category crossentropy by epochs\relax }{figure.caption.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.19}{\ignorespaces Models train and validation top k accuracy by epochs\relax }}{61}{figure.caption.60}}
\newlabel{img:4CNN_top_k_accuracy}{{4.19}{61}{Models train and validation top k accuracy by epochs\relax }{figure.caption.60}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.20}{\ignorespaces Models batch time by epochs\relax }}{62}{figure.caption.61}}
\newlabel{img:4CNN_timing}{{4.20}{62}{Models batch time by epochs\relax }{figure.caption.61}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.21}{\ignorespaces Convolutional models with modification (a) 1;(b) 2; (c) 3; (d) 4. Histogram of convolution layers\relax }}{62}{figure.caption.62}}
\newlabel{img:Convolutional models with modification convolution layers}{{4.21}{62}{Convolutional models with modification (a) 1;(b) 2; (c) 3; (d) 4. Histogram of convolution layers\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.22}{\ignorespaces Convolutional models with modification (a) 1;(b) 2; (c) 3; (d) 4. Histogram of merged layers\relax }}{63}{figure.caption.63}}
\newlabel{img:Convolutional models with modification merged layers}{{4.22}{63}{Convolutional models with modification (a) 1;(b) 2; (c) 3; (d) 4. Histogram of merged layers\relax }{figure.caption.63}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.23}{\ignorespaces Convolutional models with modification (a) 1;(b) 2; (c) 3; (d) 4. Histogram of dense layers\relax }}{64}{figure.caption.64}}
\newlabel{img:Convolutional models with modification Histogram of dense layers}{{4.23}{64}{Convolutional models with modification (a) 1;(b) 2; (c) 3; (d) 4. Histogram of dense layers\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Final model}{65}{section.4.5}}
\newlabel{sect4_5}{{4.5}{65}{Final model}{section.4.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Final results\relax }}{65}{table.caption.65}}
\newlabel{my-label}{{4.7}{65}{Final results\relax }{table.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.24}{\ignorespaces Models train and validation categorical accuracy by epochs\relax }}{66}{figure.caption.66}}
\newlabel{img:final_CNN_categorical_accuracy}{{4.24}{66}{Models train and validation categorical accuracy by epochs\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.25}{\ignorespaces Models train and validation category crossentropy by epochs\relax }}{66}{figure.caption.67}}
\newlabel{img:final_CNN_category_crossentropy}{{4.25}{66}{Models train and validation category crossentropy by epochs\relax }{figure.caption.67}{}}
\gdef \LT@i {\LT@entry 
    {1}{63.4356pt}\LT@entry 
    {1}{65.01059pt}\LT@entry 
    {1}{44.37381pt}\LT@entry 
    {1}{57.77597pt}\LT@entry 
    {1}{58.54515pt}}
\gdef \FBLTpage@i {\gdef\flrow@LTlastpage{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.26}{\ignorespaces Models train and validation top k accuracy by epochs\relax }}{67}{figure.caption.68}}
\newlabel{img:final_CNN_top_k_accuracy}{{4.26}{67}{Models train and validation top k accuracy by epochs\relax }{figure.caption.68}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Classification report}}{67}{table.4.8}}
\newlabel{tab:amortecimentos_1}{{4.8}{67}{Classification report}{table.4.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Summary of the section}{68}{section.4.6}}
\newlabel{sect4_6}{{4.6}{68}{Summary of the section}{section.4.6}{}}
\@writefile{toc}{\contentsline {chapter}{CONCLUSIONS}{69}{chapter*.69}}
\bibdata{../biblio/othercites}
\bibcite{manning}{1}
\bibcite{foundationsml}{2}
\bibcite{NB1}{3}
\bibcite{NB2}{4}
\bibcite{LR}{5}
\bibcite{svm}{6}
\bibcite{model_evaluation}{7}
\bibcite{jurafsky}{8}
\bibcite{embeddings_1}{9}
\bibcite{embeddings_2}{10}
\bibcite{assignment1}{11}
\bibcite{CNN}{12}
\bibcite{Kalchbrenner}{13}
\bibcite{CNN_habr}{14}
\@writefile{toc}{\contentsline {chapter}{BIBLIOGRAPHY}{70}{section*.70}}
\bibcite{wiki_def_rnn}{15}
\bibcite{colah_lstm}{16}
\bibcite{rnn_problems}{17}
\bibcite{wildml}{18}
\bibcite{fasttext}{19}
\@writefile{toc}{\contentsline {chapter}{LIST OF FIGURES}{72}{section*.72}}
\@writefile{toc}{\contentsline {chapter}{LIST OF TABLES}{74}{section*.73}}
\@writefile{toc}{\contentsline {chapter}{APPENDIX A ILLUSTRATIVE MATERIAL}{75}{appendix*.74}}
\@writefile{toc}{\contentsline {chapter}{APPENDIX B DATA SAMPLES}{88}{appendix*.75}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Classification report}}{88}{table.Alph0.9}}
\newlabel{tab:amortecimentos}{{9}{88}{Classification report}{table.Alph0.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Classification report}}{89}{table.Alph0.9}}
\newlabel{tab:amortecimentos}{{9}{89}{Classification report}{table.Alph0.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Classification report}}{90}{table.Alph0.9}}
\newlabel{tab:amortecimentos}{{9}{90}{Classification report}{table.Alph0.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Classification report}}{91}{table.Alph0.9}}
\newlabel{tab:amortecimentos}{{9}{91}{Classification report}{table.Alph0.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Classification report}}{92}{table.Alph0.9}}
\newlabel{tab:amortecimentos}{{9}{92}{Classification report}{table.Alph0.9}{}}
\gdef \LT@ii {\LT@entry 
    {1}{63.4356pt}\LT@entry 
    {1}{65.01059pt}\LT@entry 
    {1}{44.37381pt}\LT@entry 
    {1}{57.77597pt}\LT@entry 
    {1}{58.54515pt}}
\gdef \FBLTpage@ii {\gdef\flrow@LTlastpage{6}}
\expandafter\ifx\csname c@citenum@totc\endcsname\relax\newcounter{citenum@totc}\fi\setcounter{citenum@totc}{19}
\providecommand\totalcount@set[2]{}
\totalcount@set{figure}{49}
\totalcount@set{table}{18}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Classification report}}{93}{table.Alph0.9}}
\newlabel{tab:amortecimentos}{{9}{93}{Classification report}{table.Alph0.9}{}}
\newlabel{img:cnn_architecture}{{\caption@xref {img:cnn_architecture}{ on input line 31}}{94}{APPENDIX B DATA SAMPLES}{figure.caption.76}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Architectures of CNN model\relax }}{94}{figure.caption.76}}
\newlabel{TotPages}{{82}{94}{}{page.94}{}}
\expandafter\ifx\csname c@totalcount@figure@totc\endcsname\relax\newcounter{totalcount@figure@totc}\fi\setcounter{totalcount@figure@totc}{49}
\expandafter\ifx\csname c@totalcount@table@totc\endcsname\relax\newcounter{totalcount@table@totc}\fi\setcounter{totalcount@table@totc}{18}
\expandafter\ifx\csname c@TotPages@totc\endcsname\relax\newcounter{TotPages@totc}\fi\setcounter{TotPages@totc}{82}
