\clearpage                                  % В том числе гарантирует, что список литературы в оглавлении будет с правильным номером страницы
\phantomsection
\addcontentsline{toc}{chapter}{\bibname}	% Добавляем список литературы в оглавление
%\hypersetup{ urlcolor=black }               % Ссылки делаем чёрными
%\providecommand*{\BibDash}{}                % В стилях ugost2008 отключаем использование тире как разделителя 
\urlstyle{rm}                               % ссылки URL обычным шрифтом
\insertbiblioother                          % Подключаем Bib-базы
\urlstyle{tt}                               % возвращаем установки шрифта ссылок URL
%\hypersetup{ urlcolor={urlcolor} }          % Восстанавливаем цвет ссылок


\begin{thebibliography}
	{1} 
	\bibitem{jurafsky} Jurafsky D. Speech and Language Processing / D. Jurafsky, M. James   H. – New Jersey, 2008. – 1031 с. – (Pearson). – (ISBN: 0131873210). 
	 {2}
	 \bibitem{manning} Manning C. An Introduction to Information Retrieval / C. Manning, P. Raghavan, H. Schütze. – Cambridge, England: Online edition, 2009. – 544 p. – (Cambridge University Press).  (ISBN: 0521865719).
	 {3}
	 \bibitem{foundationsml}  Mohri M. Foundations of Machine Learning / M. Mohri, A. Rostamizadeh, A. Talwalkar. – Cambridge, Massachusetts, 2012. – 412 с. – (The MIT Press). – (ISBN: 9780262018258).
	 {4}
	 \bibitem{handsonml} Géron A. Hands-On Machine Learning with Scikit- Learn and TensorFlow / Aurélien Géron. – Gravenstein Highway North, Sebastopol, CA, 2017. – 751 с. – (O’Reilly Media). – (ISBN: 8009989938).
	 {5}
	 \bibitem{LR}Yang, Yiming, and Xin Liu. 1999. A re-examination of text categorization methods.
	 In Proc. SIGIR, pp. 42–49. ACM Press. 2
	 {}
	 \bibitem{NB1}McCallum, Andrew, and Kamal Nigam. 1998. A comparison of event models for
	 Naive Bayes text classification. In AAAI/ICML Workshop on Learning for Text Categorization,
	 pp. 41–48.
	 {}
	 \bibitem{NB2}Rennie, Jason D., Lawrence Shih, Jaime Teevan, and David R. Karger. 2003. Tackling
	 the poor assumptions of naive Bayes text classifiers. In Proc. ICML, pp. 616–623.
	 {}
	  \bibitem{svm}Tong, Simon, and Daphne Koller. 2001. Support vector machine active learning with
	 applications to text classification. JMLR 2:45–66
	 {}
	 \bibitem{embeddings_1}https://arxiv.org/pdf/1301.3781.pdf
	 {}
	 \bibitem{embeddings_2}https://arxiv.org/pdf/1310.4546.pdf
	 {}
	 \bibitem{info_retrievel}Zavrel, Jakub, Peter Berck, and Willem Lavrijssen. 2000. Information extraction by text classification: Corpus mining for features. In Workshop Information Extraction
	 Meets Corpus Linguistics. URL: www.cnts.ua.ac.be/Publications/2000/ZBL00. Held in
	 conjunction with LREC-2000.
	 {}
	 \bibitem{assignment1} Assignment 1[Course assignment]. (2016). Retrieved from http://cs224d.stanford.edu/assignment1/assignment1.pdf 
	 {}
	 \bibitem{cbow_skip}
	 \bibitem{CNN}
%	 \bibitem{cbow_skip} 
%	    @ARTICLE{2013arXiv1301.3781M,
%	 	author = {{Mikolov}, T. and {Chen}, K. and {Corrado}, G. and {Dean}, J.
%	 	},
%	 	title = "{Efficient Estimation of Word Representations in Vector Space}",
%	 	journal = {ArXiv e-prints},
%	 	archivePrefix = "arXiv",
%	 	eprint = {1301.3781},
%	 	primaryClass = "cs.CL",
%	 	keywords = {Computer Science - Computation and Language},
%	 	year = 2013,
%	 	month = jan,
%	 	adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1301.3781M},
%	 	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
%	 }	
%	 \bibitem{CNN}
%		@ARTICLE{2014arXiv1408.5882K,
%	 	author = {{Kim}, Y.},
%	 	title = "{Convolutional Neural Networks for Sentence Classification}",
%	 	journal = {ArXiv e-prints},
%	 	archivePrefix = "arXiv",
%	 	eprint = {1408.5882},
%	 	primaryClass = "cs.CL",
%	 	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
%	 	year = 2014,
%	 	month = aug,
%	 	adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1408.5882K},
%	 	adsnote = {Provided by the SAO/NASA Astrophysics Data System}
%	 	}	
	\bibitem{CNN_habr}
		Kalinin S. (2017, December, 7). Convolution neural networks with python.[Blog post]. Retrieved from https://habrahabr.ru/company/ods/blog/344008/
	\bibitem{model_evaluation}
		Raschka S. (2016, June, 11) Model evaluation, model selection, and algorithm selection in machine learning. [Blog post]. Retrieved from
		https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html
	\bibitem{fasttext} P. Bojanowski*, E. Grave*, A. Joulin, T. Mikolov, Enriching Word Vectors with Subword Information

	\bibitem{kim}Kim, Y. (2014). Convolutional Neural Networks for Sentence Classification. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014), 1746–1751.
	
	\bibitem{Kalchbrenner}Kalchbrenner, N., Grefenstette, E.,  Blunsom, P. (2014). A Convolutional Neural Network for Modelling Sentences. Acl, 655–665.
	
	\bibitem{wildml}http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/
	\bibitem{wiki_def_rnn}https://en.wikipedia.org/wiki/Recurrent\_neural\_network 
	\bibitem{colah_lstm}http://colah.github.io/posts/2015-08-Understanding-LSTMs/
	\bibitem{rnn_problems}https://arxiv.org/pdf/1211.5063.pdf
	
\end{thebibliography}
%https://academicguides.waldenu.edu/writingcenter/apa/references/examples